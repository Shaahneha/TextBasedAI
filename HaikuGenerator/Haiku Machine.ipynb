{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b34110fc",
   "metadata": {},
   "source": [
    "# A simple haiku generator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b859537",
   "metadata": {},
   "source": [
    "### Traditional Haiku Structure\n",
    "The structure of a traditional haiku is always the same, including the following features:\n",
    "\n",
    "There are only three lines, totaling 17 syllables.\n",
    "The first line is 5 syllables.\n",
    "The second line is 7 syllables.\n",
    "The third line is 5 syllables like the first.\n",
    "Punctuation and capitalization are up to the poet, and need not follow the rigid rules used in structuring sentences.\n",
    "A haiku does not have to rhyme, in fact usually it does not rhyme at all.\n",
    "It can include the repetition of words or sounds\n",
    "\n",
    "Note: we are counting syllables and not words. \n",
    "\n",
    "The 5-7-5 rhythm has been lost in translation, as not every Japanese word has the same number of syllables, or sounds, as its English version. For example, haiku has two syllables in English. In Japanese, the word has three sounds\n",
    "\n",
    "The work here is inspired by Sean Zhai\n",
    "https://reddotblues.medium.com/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1e610",
   "metadata": {},
   "source": [
    "#### setup (if not already installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c24f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U spacy\n",
    "#!pip3 install syllapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf03e2",
   "metadata": {},
   "source": [
    "#### import relevant libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3f0f140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import syllapy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765969b",
   "metadata": {},
   "source": [
    "#### create patterns\n",
    "\n",
    "Used the spacy's rule based matcher by creating token patterns and running them over our text\n",
    "\n",
    "these matchers can be generated using the tool \n",
    "https://demos.explosion.ai/matcher?text=A%20match%20is%20a%20tool%20for%20starting%20a%20fire.%20Typically%2C%20modern%20matches%20are%20made%20of%20small%20wooden%20sticks%20or%20stiff%20paper.%20One%20end%20is%20coated%20with%20a%20material%20that%20can%20be%20ignited%20by%20frictional%20heat%20generated%20by%20striking%20the%20match%20against%20a%20suitable%20surface.%20Wooden%20matches%20are%20packaged%20in%20matchboxes%2C%20and%20paper%20matches%20are%20partially%20cut%20into%20rows%20and%20stapled%20into%20matchbooks.&model=en_core_web_sm&pattern=%5B%7B%22id%22%3A0%2C%22attrs%22%3A%5B%7B%22name%22%3A%22POS%22%2C%22value%22%3A%22ADJ%22%7D%2C%7B%22name%22%3A%22OP%22%2C%22value%22%3A%22%3F%22%7D%5D%7D%2C%7B%22id%22%3A1%2C%22attrs%22%3A%5B%7B%22name%22%3A%22LEMMA%22%2C%22value%22%3A%22match%22%7D%2C%7B%22name%22%3A%22POS%22%2C%22value%22%3A%22NOUN%22%7D%5D%7D%2C%7B%22id%22%3A2%2C%22attrs%22%3A%5B%7B%22name%22%3A%22LEMMA%22%2C%22value%22%3A%22be%22%7D%5D%7D%5D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6295802",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.max_length = 1000000000000;\n",
    "matcher2 = Matcher(nlp.vocab)\n",
    "matcher3 = Matcher(nlp.vocab)\n",
    "matcher4 = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\"]} }]\n",
    "matcher2.add(\"TwoWords\", [pattern])\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]} }]\n",
    "matcher3.add(\"ThreeWords\", [pattern])\n",
    "pattern = [{'POS':  {\"IN\": [\"NOUN\", \"ADP\", \"ADJ\", \"ADV\"]} },\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'IS_ASCII': True, 'IS_PUNCT': False, 'IS_SPACE': False},\n",
    "           {'POS':  {\"IN\": [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"]} }]\n",
    "matcher4.add(\"FourWords\", [pattern])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348741d0",
   "metadata": {},
   "source": [
    "#### load data\n",
    "Here I am using a text file for one of the famous novels. This will be used as refernece for creating haiku\n",
    "I downloaded one from https://www.gutenberg.org/ in text UTF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c19e4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r\"HaikuGenerator\\data\\GreatExpectations.txt\"\n",
    "doc = nlp(open(file,encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfce782",
   "metadata": {},
   "source": [
    "#### create matches for syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16417a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches2 = matcher2(doc)\n",
    "matches3 = matcher3(doc)\n",
    "matches4 = matcher4(doc)\n",
    "\n",
    "g_5 = []\n",
    "g_7 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a58d6",
   "metadata": {},
   "source": [
    "#### create sets of 5 and 7 syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "defe98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter for a new haiku. ^C to quit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches2 + matches3 + matches4:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "\n",
    "    syl_count = 0\n",
    "    for token in span:\n",
    "        syl_count += syllapy.count(token.text)\n",
    "    if syl_count == 5:\n",
    "        if span.text not in g_5:\n",
    "            g_5.append(span.text)\n",
    "    if syl_count == 7:\n",
    "        if span.text not in g_7:\n",
    "            g_7.append(span.text)\n",
    "print(\"Enter for a new haiku. ^C to quit\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b6c43",
   "metadata": {},
   "source": [
    "#### Keep generating Haikus :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e4103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes were holden\n",
      "attentively engaged\n",
      "previously been quite\n",
      "\n",
      "\n",
      "attempts at pieces\n",
      "out in his accustomed\n",
      "seldom if ever\n",
      "\n",
      "\n",
      "in which country boys\n",
      "set of ivory tablets\n",
      "slowly unclenched\n",
      "\n",
      "\n",
      "laws regulating\n",
      "exemplary transactions\n",
      "knife many a time\n",
      "\n",
      "\n",
      "baby on her lap\n",
      "O equal to anythink\n",
      "to the first figure\n"
     ]
    }
   ],
   "source": [
    "while (True):\n",
    "    print(\"%s\\n%s\\n%s\" %(random.choice(g_5),random.choice(g_7),random.choice(g_5)))\n",
    "    input(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581bf483",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
